{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dd37e20",
   "metadata": {},
   "source": [
    "# PLEASE READ\n",
    "This app is designed to be run using Streamlit, which does not support Jupyter Notebooks (.ipynb). To run this application, please follow the readme.md\n",
    "\n",
    "A Jupyter Notebook was created to hold the application for the purpose of following the rubric note: \"Submit any code you wrote as a Jupyter notebook.\"\n",
    "\n",
    "If you wish to see the exploratory code as we began to build our two pipelines, please find all code in the \"Code - Exploratory\" Folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952ea00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "from gtts import gTTS\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os\n",
    "\n",
    "## Configuration ##\n",
    "st.set_page_config(page_title=\"AAC Board Generator with Core Vocabulary\", layout=\"wide\")  # Widened layout\n",
    "\n",
    "# Paths\n",
    "CSV_PATH = \"./data/ARASAAC_symbols.csv\"\n",
    "\n",
    "# Initialize session state\n",
    "if 'result' not in st.session_state:\n",
    "    st.session_state.result = None\n",
    "if 'uploaded_image' not in st.session_state:\n",
    "    st.session_state.uploaded_image = None\n",
    "if 'core_vocab_symbols' not in st.session_state:\n",
    "    st.session_state.core_vocab_symbols = None\n",
    "\n",
    "\n",
    "# Cache so it only loads once.\n",
    "@st.cache_resource\n",
    "def load_models():\n",
    "    \"\"\"Load BLIP and sentence transformer models.\"\"\"\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    \n",
    "    # Load BLIP for image captioning\n",
    "    try:\n",
    "        blip_processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
    "        blip_model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(device)\n",
    "        blip_loaded = True\n",
    "    except Exception as e:\n",
    "        st.error(f\"Could not load BLIP model: {e}\")\n",
    "        blip_processor = None\n",
    "        blip_model = None\n",
    "        blip_loaded = False\n",
    "    \n",
    "    # Load sentence transformer\n",
    "    try:\n",
    "        sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "        sentence_model_loaded = True\n",
    "    except Exception as e:\n",
    "        st.error(f\"Could not load sentence transformer: {e}\")\n",
    "        sentence_model = None\n",
    "        sentence_model_loaded = False\n",
    "    \n",
    "    return {\n",
    "        'blip_processor': blip_processor,\n",
    "        'blip_model': blip_model,\n",
    "        'blip_loaded': blip_loaded,\n",
    "        'sentence_model': sentence_model,\n",
    "        'sentence_model_loaded': sentence_model_loaded,\n",
    "        'device': device\n",
    "    }\n",
    "\n",
    "\n",
    "@st.cache_data\n",
    "def load_csv_data():\n",
    "    \"\"\"Load and preprocess CSV data.\"\"\"\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    df = df.drop_duplicates(subset=['primary_keyword'])\n",
    "    return df\n",
    "\n",
    "\n",
    "@st.cache_data\n",
    "def precompute_embeddings(df, _sentence_model):\n",
    "    \"\"\"Pre-compute keyword embeddings.\"\"\"\n",
    "    keywords = df[\"primary_keyword\"].tolist()\n",
    "    embeddings = _sentence_model.encode(keywords, show_progress_bar=False, convert_to_numpy=True)\n",
    "    df = df.copy()\n",
    "    df[\"keyword_emb\"] = [emb for emb in embeddings]\n",
    "    return df\n",
    "\n",
    "\n",
    "def get_core_vocabulary_symbols(df):\n",
    "    \"\"\"Get core vocabulary symbols using hardcoded synset IDs from CSV.\"\"\"\n",
    "    # Hardcoded synset IDs for core vocabulary (looked up from CSV)\n",
    "    core_vocab_synsets = {\n",
    "        'i': '06841868-n',\n",
    "        'you': '',  # Empty synset\n",
    "        'want': '01829179-v',\n",
    "        'like': '01781131-v',\n",
    "        'need': '01191258-v',\n",
    "        'help': '00081834-v',\n",
    "        'yes': '07218560-n',\n",
    "        'no': '07219764-n',\n",
    "        'more': '00099891-r',\n",
    "        'stop': '08534954-n',\n",
    "        'go': '01839438-v',\n",
    "        'come': '01853188-v',\n",
    "        'good': '01133477-a',\n",
    "        'bad': '01129296-a',\n",
    "        'happy': '01151786-a',\n",
    "        'sad': '01364779-a',\n",
    "        'please': '00010428-r',\n",
    "        'who': '01379820-a',\n",
    "        'how': '',  # Empty synset\n",
    "        'can': '02950393-n',\n",
    "        'make': '01622033-v',\n",
    "        'see': '02133754-v',\n",
    "        'get': '02531751-v',\n",
    "        'have': '02209474-v'\n",
    "    }\n",
    "    \n",
    "    core_symbols = []\n",
    "    \n",
    "    # Look up each synset in the dataframe\n",
    "    for word, synset_id in core_vocab_synsets.items():\n",
    "        if synset_id:\n",
    "            # Match by synset\n",
    "            matches = df[df['synset'] == synset_id]\n",
    "        else:\n",
    "            # For empty synsets, match by primary_keyword (case-insensitive, single word)\n",
    "            matches = df[\n",
    "                (df['primary_keyword'].str.lower() == word.lower()) &\n",
    "                (~df['primary_keyword'].str.contains(r'\\s', regex=True, na=False))\n",
    "            ]\n",
    "        \n",
    "        if not matches.empty:\n",
    "            row = matches.iloc[0]\n",
    "            core_symbols.append({\n",
    "                'synset': row['synset'],\n",
    "                'pictogram_id': row['pictogram_id'],\n",
    "                'primary_keyword': row['primary_keyword'],\n",
    "                'image_url': row['image_url'],\n",
    "                'keyword_list': [row['primary_keyword']],\n",
    "                'is_core': True\n",
    "            })\n",
    "        else:\n",
    "            print(f\"Warning: Could not find symbol for core word: {word} (synset: {synset_id})\")\n",
    "    \n",
    "    return core_symbols\n",
    "\n",
    "\n",
    "def caption_image(image, models):\n",
    "    \"\"\"Generate caption from image using BLIP.\"\"\"\n",
    "    if not models['blip_loaded']:\n",
    "        raise Exception(\"BLIP model not loaded\")\n",
    "    \n",
    "    image = image.convert(\"RGB\")\n",
    "    inputs = models['blip_processor'](images=image, return_tensors=\"pt\").to(models['device'])\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = models['blip_model'].generate(**inputs, max_length=30, num_beams=5, repetition_penalty=1.15)\n",
    "    \n",
    "    caption = models['blip_processor'].decode(out[0], skip_special_tokens=True).strip()\n",
    "    return caption\n",
    "\n",
    "\n",
    "def text_to_board(text, df_with_embeddings, sentence_model, top_n=20):\n",
    "    \"\"\"Convert text to ranked symbols using sentence transformers.\"\"\"\n",
    "    # Encode input text\n",
    "    text_emb = sentence_model.encode(text, convert_to_numpy=True)\n",
    "    \n",
    "    # Calculate similarity scores (cosine similarity)\n",
    "    df_with_embeddings = df_with_embeddings.copy()\n",
    "    df_with_embeddings[\"score\"] = df_with_embeddings[\"keyword_emb\"].apply(\n",
    "        lambda emb: np.dot(text_emb, emb) / (np.linalg.norm(text_emb) * np.linalg.norm(emb)))\n",
    "    \n",
    "    # Sort by score and get top N\n",
    "    df_sorted = df_with_embeddings.sort_values(\"score\", ascending=False)\n",
    "    top_results = df_sorted.head(top_n * 2)  # Get more to account for duplicates\n",
    "    \n",
    "    # Extract unique symbols (prefer highest scoring)\n",
    "    symbols = []\n",
    "    seen_synsets = set()\n",
    "    for _, row in top_results.iterrows():\n",
    "        synset = row['synset']\n",
    "        if synset not in seen_synsets:\n",
    "            symbols.append({\n",
    "                'synset': synset,\n",
    "                'pictogram_id': row['pictogram_id'],\n",
    "                'primary_keyword': row['primary_keyword'],\n",
    "                'image_url': row['image_url'],\n",
    "                'keyword_list': [row['primary_keyword']],  # Format for compatibility\n",
    "                'score': row['score'],\n",
    "                'is_core': False\n",
    "            })\n",
    "            seen_synsets.add(synset)\n",
    "            if len(symbols) >= top_n:\n",
    "                break\n",
    "    \n",
    "    return symbols\n",
    "\n",
    "\n",
    "def display_symbol_grid(symbols, cols_per_row=6, section_title=\"\", key_prefix=\"\"):\n",
    "    \"\"\"Display symbols in a grid layout.\"\"\"\n",
    "    if not symbols:\n",
    "        return\n",
    "    \n",
    "    if section_title:\n",
    "        st.subheader(section_title)\n",
    "    \n",
    "    for row_start in range(0, len(symbols), cols_per_row):\n",
    "        cols = st.columns(cols_per_row)\n",
    "        \n",
    "        for idx, col in enumerate(cols):\n",
    "            symbol_idx = row_start + idx\n",
    "            if symbol_idx < len(symbols):\n",
    "                symbol = symbols[symbol_idx]\n",
    "                \n",
    "                with col:\n",
    "                    # Display image\n",
    "                    st.image(symbol['image_url'], use_container_width=True)\n",
    "                    \n",
    "                    # Keyword label\n",
    "                    keyword = symbol['keyword_list'][0] if symbol['keyword_list'] else symbol.get('primary_keyword', 'N/A')\n",
    "                    st.markdown(f\"**{keyword}**\", unsafe_allow_html=True)\n",
    "                    \n",
    "                    # Audio button\n",
    "                    if st.button(f\"ðŸ”Š\", key=f\"{key_prefix}_audio_{symbol_idx}\"):\n",
    "                        try:\n",
    "                            tts = gTTS(text=keyword, lang='en', slow=False)\n",
    "                            \n",
    "                            with tempfile.NamedTemporaryFile(delete=False, suffix='.mp3') as fp:\n",
    "                                tts.save(fp.name)\n",
    "                                st.audio(fp.name, format='audio/mp3', autoplay=True)\n",
    "                            \n",
    "                        except Exception as e:\n",
    "                            st.warning(f\"Could not generate audio for '{keyword}'\")\n",
    "\n",
    "\n",
    "# Load models and data\n",
    "models = load_models()\n",
    "df = load_csv_data()\n",
    "\n",
    "# Pre-compute embeddings if sentence model is loaded\n",
    "if models['sentence_model_loaded']:\n",
    "    df_with_embeddings = precompute_embeddings(df, models['sentence_model'])\n",
    "else:\n",
    "    df_with_embeddings = None\n",
    "\n",
    "# Load core vocabulary symbols once\n",
    "if st.session_state.core_vocab_symbols is None:\n",
    "    with st.spinner(\"Loading core vocabulary...\"):\n",
    "        st.session_state.core_vocab_symbols = get_core_vocabulary_symbols(df)\n",
    "\n",
    "# App Title\n",
    "st.title(\"Dynamic AAC Board Generator with Core Vocabulary\")\n",
    "st.write(\"Generate communication boards from images or text descriptions with built-in core vocabulary\")\n",
    "\n",
    "# Sidebar for input selection AND image display\n",
    "with st.sidebar:\n",
    "    st.header(\"âš™ï¸ Controls\")\n",
    "\n",
    "    input_type = st.radio(\"Input Type:\", [\"Upload Image\", \"Text Description\"])\n",
    "    \n",
    "    # Specificity slider (Matt's feature)\n",
    "    specificity = st.slider(\"Specificity (number of symbols):\", 10, 30, 20, 1)\n",
    "    \n",
    "    # Core vocabulary display options\n",
    "    st.markdown(\"---\")\n",
    "    st.header(\"ðŸ“‹ Core Vocabulary\")\n",
    "    show_core_vocab = st.checkbox(\"Show Core Vocabulary\", value=True)\n",
    "    core_cols = st.slider(\"Core vocab symbols per row:\", 4, 10, 6, 1)\n",
    "\n",
    "    # Show uploaded image in sidebar if it exists.\n",
    "    if st.session_state.uploaded_image:\n",
    "        st.image(st.session_state.uploaded_image, caption=\"Current Image\", use_container_width=True)\n",
    "\n",
    "    # Clear board button.\n",
    "    if st.session_state.result:\n",
    "        if st.button(\"ðŸ—‘ï¸ Clear Board\"):\n",
    "            st.session_state.result = None\n",
    "            st.session_state.uploaded_image = None\n",
    "            st.rerun()\n",
    "\n",
    "# Main content area\n",
    "if input_type == \"Upload Image\":\n",
    "    uploaded_file = st.file_uploader(\"Choose an image\", type=['jpg', 'jpeg', 'png'])\n",
    "\n",
    "    if uploaded_file:\n",
    "        # Store image in session state.\n",
    "        image = Image.open(uploaded_file)\n",
    "        st.session_state.uploaded_image = image\n",
    "\n",
    "        if st.button(\"Generate Board\", type=\"primary\"):\n",
    "            if not models['blip_loaded']:\n",
    "                st.error(\"BLIP model not available. Please install transformers.\")\n",
    "            elif not models['sentence_model_loaded']:\n",
    "                st.error(\"Sentence transformer model not available.\")\n",
    "            else:\n",
    "                with st.spinner(\"Generating AAC board...\"):\n",
    "                    # Generate caption from image using BLIP\n",
    "                    caption = caption_image(image, models)\n",
    "                    st.info(f\"Generated caption: {caption}\")\n",
    "                    \n",
    "                    # Convert caption to board using sentence transformers\n",
    "                    board = text_to_board(caption, df_with_embeddings, models['sentence_model'], top_n=specificity)\n",
    "                    \n",
    "                    st.session_state.result = {\n",
    "                        'captions': [caption],\n",
    "                        'combined_caption': caption,\n",
    "                        'board': board\n",
    "                    }\n",
    "                    st.success(f\"Generated {len(board)} symbols!\")\n",
    "\n",
    "else:  # Text Description\n",
    "    text_input = st.text_area(\"Enter scenario description:\",\n",
    "                              placeholder=\"e.g., Children playing at the playground\",\n",
    "                              height=100)\n",
    "\n",
    "    if st.button(\"Generate Board\", type=\"primary\") and text_input:\n",
    "        if not models['sentence_model_loaded']:\n",
    "            st.error(\"Sentence transformer model not available.\")\n",
    "        else:\n",
    "            with st.spinner(\"Generating AAC board...\"):\n",
    "                # Use text-to-board pipeline with sentence transformers\n",
    "                board = text_to_board(text_input, df_with_embeddings, models['sentence_model'], top_n=specificity)\n",
    "\n",
    "                st.session_state.result = {\n",
    "                    'captions': [text_input],\n",
    "                    'combined_caption': text_input,\n",
    "                    'board': board\n",
    "                }\n",
    "                st.session_state.uploaded_image = None  # Clear image when using text.\n",
    "                st.success(f\"Generated {len(board)} symbols!\")\n",
    "\n",
    "# Display Core Vocabulary (always shown if enabled)\n",
    "if show_core_vocab and st.session_state.core_vocab_symbols:\n",
    "    st.markdown(\"---\")\n",
    "    st.header(\"ðŸ“‹ Core Vocabulary\")\n",
    "    st.write(\"Essential words for communication - always available\")\n",
    "    \n",
    "    display_symbol_grid(\n",
    "        st.session_state.core_vocab_symbols,\n",
    "        cols_per_row=core_cols,\n",
    "        key_prefix=\"core\"\n",
    "    )\n",
    "\n",
    "# Display Dynamic Board - use session_state result.\n",
    "if st.session_state.result:\n",
    "    result = st.session_state.result\n",
    "\n",
    "    st.markdown(\"---\")\n",
    "    st.subheader(\"ðŸŽ¯ Context-Specific Symbols\")\n",
    "    st.write(f\"**Scene:** {result['combined_caption']}\")\n",
    "\n",
    "    # Show more symbols with responsive columns\n",
    "    num_symbols = st.slider(\"Number of symbols to display:\", 8, len(result['board']), min(24, len(result['board'])), 4)\n",
    "    cols_per_row = st.slider(\"Symbols per row:\", 4, 8, 6, 1)\n",
    "\n",
    "    board = result['board'][:num_symbols]\n",
    "    st.write(f\"Displaying {len(board)} of {len(result['board'])} total symbols\")\n",
    "\n",
    "    display_symbol_grid(\n",
    "        board,\n",
    "        cols_per_row=cols_per_row,\n",
    "        key_prefix=\"dynamic\"\n",
    "    )\n",
    "\n",
    "else:\n",
    "    # Welcome message\n",
    "    if not show_core_vocab or not st.session_state.core_vocab_symbols:\n",
    "        st.info(\"Upload an image or enter a text description to generate an AAC board\")\n",
    "    else:\n",
    "        st.info(\"Upload an image or enter a text description to generate context-specific symbols. Core vocabulary is shown above.\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
